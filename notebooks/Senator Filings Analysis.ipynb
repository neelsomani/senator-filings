{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senator Filings Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "from functools import lru_cache\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we explore stock orders that were publicly filed by U.S. senators. The filings are scraped from https://efdsearch.senate.gov/search/. We calculate the returns of each senator by mimicking their buys and sells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The `senators.pickle` file is scraped using the script in the root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'senators.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msenators.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     raw_senators_tx \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\Users\\ndcar\\anaconda3\\envs\\senate\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'senators.pickle'"
     ]
    }
   ],
   "source": [
    "with open('senators.pickle', 'rb') as f:\n",
    "    raw_senators_tx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fill in as many of the missing ticker symbols as we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_senators_tx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblacklist.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m     blacklist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(json\u001b[38;5;241m.\u001b[39mload(f))\n\u001b[1;32m---> 17\u001b[0m missing_tickers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mraw_senators_tx\u001b[49m[\n\u001b[0;32m     18\u001b[0m     (raw_senators_tx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;241m|\u001b[39m (raw_senators_tx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m ][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m ticker_map \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     23\u001b[0m unmapped_tickers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_senators_tx' is not defined"
     ]
    }
   ],
   "source": [
    "def tokenize(asset_name):\n",
    "    \"\"\" Convert an asset name into useful tokens. \"\"\"\n",
    "    token_string = asset_name\\\n",
    "        .replace('(', '')\\\n",
    "        .replace(')', '')\\\n",
    "        .replace('-', ' ')\\\n",
    "        .replace('.', '')\n",
    "    return token_string.split(' ')\n",
    "\n",
    "def token_is_ticker(token, token_blacklist):\n",
    "    return len(token) <= 4 and token.upper() not in token_blacklist\n",
    "\n",
    "# These generic words do not help us determine the ticker\n",
    "with open('blacklist.json', 'r') as f:\n",
    "    blacklist = set(json.load(f))\n",
    "\n",
    "missing_tickers = set(raw_senators_tx[\n",
    "    (raw_senators_tx['ticker'] == '--')\n",
    "    | (raw_senators_tx['ticker'] == '')\n",
    "]['asset_name'])\n",
    "\n",
    "ticker_map = {}\n",
    "unmapped_tickers = set()\n",
    "for m in missing_tickers:\n",
    "    tokens = tokenize(m)\n",
    "    if token_is_ticker(tokens[0], blacklist):\n",
    "        ticker_map[m] = tokens[0].upper()\n",
    "    elif token_is_ticker(tokens[-1], blacklist):\n",
    "        ticker_map[m] = tokens[-1].upper()\n",
    "    else:\n",
    "        unmapped_tickers.add(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second pass, we assign tickers to asset names that have any of the specified keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase_to_ticker = {\n",
    "    'FOX': 'FOX',\n",
    "    'AMAZON': 'AMZN',\n",
    "    'AARON': 'AAN',\n",
    "    'ALTRIA': 'MO',\n",
    "    'APPLE': 'AAPL',\n",
    "    'CHEVRON': 'CVX',\n",
    "    'DUPONT': 'DD',\n",
    "    'ALPHABET': 'GOOGL',\n",
    "    'GOOG': 'GOOGL',\n",
    "    'GENERAL ELECTRIC': 'GE',\n",
    "    'JOHNSON': 'JNJ',\n",
    "    'NEWELL': 'NWL',\n",
    "    'OWENS': 'OMI',\n",
    "    'PFIZER': 'PFE',\n",
    "    'TYSON': 'TSN',\n",
    "    'UNDER ARMOUR': 'UAA',\n",
    "    'VERIZON': 'VZ',\n",
    "    'WALT': 'DIS'\n",
    "}\n",
    "\n",
    "for m in unmapped_tickers:\n",
    "    for t in phrase_to_ticker:\n",
    "        if t in m.upper():\n",
    "            ticker_map[m] = phrase_to_ticker[t]\n",
    "\n",
    "tx_with_tickers = raw_senators_tx.copy()\n",
    "for a, t in ticker_map.items():\n",
    "    tx_with_tickers.loc[tx_with_tickers['asset_name'] == a, 'ticker'] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out useless rows and missing symbols, and then add some useful columns for the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_tx = tx_with_tickers[tx_with_tickers['ticker'] != '--']\n",
    "filtered_tx = filtered_tx.assign(\n",
    "    ticker=filtered_tx['ticker'].map(\n",
    "        lambda s: s.replace('--', '').replace('\\n', '')))\n",
    "\n",
    "filtered_tx = filtered_tx[filtered_tx['order_type'] != 'Exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_tx_amount(amt):\n",
    "    \"\"\" Get the lower bound for the transaction amount. \"\"\"\n",
    "    return int(amt.replace('Over $50,000,000', '50000000')\n",
    "               .split(' - ')[0]\n",
    "               .replace(',', '')\n",
    "               .replace('$', ''))\n",
    "\n",
    "senators_tx = filtered_tx.assign(\n",
    "    tx_estimate=filtered_tx['tx_amount'].map(parse_tx_amount))\n",
    "senators_tx = senators_tx.assign(\n",
    "    full_name=senators_tx['first_name']\n",
    "        .str\n",
    "        .cat(senators_tx['last_name'], sep=' ')\n",
    ")\n",
    "useful_cols = [\n",
    "    'file_date',\n",
    "    'tx_date',\n",
    "    'full_name',\n",
    "    'order_type',\n",
    "    'ticker',\n",
    "    'tx_estimate'\n",
    "]\n",
    "senators_tx = senators_tx[useful_cols]\n",
    "senators_tx = senators_tx.assign(\n",
    "    tx_date=senators_tx['tx_date'].map(\n",
    "        lambda v: dt.datetime.strptime(v.strip(), '%m/%d/%Y')))\n",
    "senators_tx = senators_tx.assign(\n",
    "    file_date=senators_tx['file_date'].map(\n",
    "        lambda v: dt.datetime.strptime(v.strip(), '%m/%d/%Y')))\n",
    "senators_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells help us download the market data for the specified tickers. We store the market data in files so we don't need to repeatedly download the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_for_ticker(ticker, check_cache=True):\n",
    "    \"\"\" Download a file of stock prices for this ticker to disk. \"\"\"\n",
    "    if check_cache and os.path.exists('stocks/{0}.pickle'.format(ticker)):\n",
    "        return\n",
    "    d = yf.Ticker(ticker)\n",
    "    with open('stocks/{0}.pickle'.format(ticker), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'price': d.history(period='max').reset_index()\n",
    "        }, f)\n",
    "\n",
    "def load_for_ticker(ticker):\n",
    "    \"\"\" Load the file of stock prices for this ticker. \"\"\"\n",
    "    with open('stocks/{0}.pickle'.format(ticker), 'rb') as f:\n",
    "        dump = pickle.load(f)\n",
    "    raw = dump['price']\n",
    "    return raw[['Date', 'Close']]\\\n",
    "        .rename(columns={'Date': 'date', 'Close': 'price'})\n",
    "\n",
    "def _price_for_date(df, date):\n",
    "    \"\"\" Helper function for `ticker_at_date`. \"\"\"\n",
    "    df = df[df['date'] >= date].sort_values(by='date')\n",
    "    return df['price'].iloc[0]\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def ticker_at_date(ticker, date):\n",
    "    \"\"\"\n",
    "    Price of a ticker at a given date. Raise an IndexError if there is no\n",
    "    such price.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = load_for_ticker(ticker)\n",
    "        # Sell at the next opportunity possible\n",
    "        return _price_for_date(data, date)\n",
    "    except Exception:\n",
    "        # If any exception occurs, refresh the cache\n",
    "        download_for_ticker(ticker, check_cache=False)\n",
    "        data = load_for_ticker(ticker)\n",
    "        return _price_for_date(data, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('stocks')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "all_tickers = set(senators_tx['ticker'])\n",
    "for i, t in enumerate(all_tickers):\n",
    "    if i % 100 == 0:\n",
    "        print('Working on ticker {0}'.format(i))\n",
    "    try:\n",
    "        download_for_ticker(t)\n",
    "    except Exception as e:\n",
    "        print('Ticker {0} failed with exception: {1}'.format(t, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimicking buy + sell orders\n",
    "\n",
    "We calculate a given senator's return by calculating the return between each buy or sell order, and then solving for the cumulative return. We convert that to a CAGR given the time period the senator was investing.\n",
    "\n",
    "We keep track of how many units of each stock a senator is holding. If we ever see a filing that indicates the senator sold more than we estimated they are holding, we just sell all of the units we have on record. (We do not allow the senator to go short.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buckets = [\n",
    "    (1000, 15000),\n",
    "    (15000, 50000),\n",
    "    (50000, 100000),\n",
    "    (100000, 250000),\n",
    "    (250000, 500000),\n",
    "    (500000, 1000000),\n",
    "    (1000000, 5000000),\n",
    "    (5000000, 25000000),\n",
    "    (25000000, 50000000),\n",
    "    (50000000, float('inf'))\n",
    "]\n",
    "\n",
    "def same_bucket(dollar_value_a, dollar_value_b):\n",
    "    \"\"\"\n",
    "    If the dollar value of the stock units is roughly the same, sell all\n",
    "    units.\n",
    "    \"\"\"\n",
    "    for v1, v2 in buckets:\n",
    "        if dollar_value_a >= v1 and dollar_value_a < v2:\n",
    "            return dollar_value_b >= v1 and dollar_value_b < v2\n",
    "    return False\n",
    "\n",
    "def portfolio_value(stocks, date):\n",
    "    \"\"\"\n",
    "    Value of a portfolio if each ticker has the specified number of units.\n",
    "    \"\"\"\n",
    "    v = 0\n",
    "    for s, units in stocks.items():\n",
    "        if units == 0:\n",
    "            continue\n",
    "        try:\n",
    "            v += ticker_at_date(s, date) * units\n",
    "        except IndexError as e:\n",
    "            # Swallow missing ticker data exception\n",
    "            pass\n",
    "    return v\n",
    "\n",
    "def calculate_return(before_values,\n",
    "                     after_values,\n",
    "                     begin_date,\n",
    "                     end_date,\n",
    "                     tx_dates):\n",
    "    \"\"\"\n",
    "    Calculate cumulative return and CAGR given the senators portfolio\n",
    "    value over time.\n",
    "    \"\"\"\n",
    "    before_values.pop(0)\n",
    "    after_values.pop(-1)\n",
    "    # We calculate the total return by calculating the return\n",
    "    # between each transaction, and solving for the cumulative\n",
    "    # return.\n",
    "    growth = np.array(before_values) / np.array(after_values)\n",
    "    portfolio_return = np.prod(growth[~np.isnan(growth)])\n",
    "    years = (end_date - begin_date).days / 365\n",
    "    if years == 0:\n",
    "        cagr = 0\n",
    "    else:\n",
    "        cagr = portfolio_return**(1 / years)\n",
    "    # DataFrame of cumulative return\n",
    "    tx_dates.pop(0)\n",
    "    tx_dates = np.array(tx_dates)\n",
    "    tx_dates = tx_dates[~np.isnan(growth)]\n",
    "    cumulative_growth = np.cumprod(growth[~np.isnan(growth)])\n",
    "    growth_df = pd.DataFrame({\n",
    "        'date': tx_dates,\n",
    "        'cumulative_growth': cumulative_growth\n",
    "    })\n",
    "    return {\n",
    "        'portfolio_return': portfolio_return,\n",
    "        'annual_cagr': cagr,\n",
    "        'growth': growth_df\n",
    "    }\n",
    "\n",
    "def return_for_senator(rows, date_col='tx_date'):\n",
    "    \"\"\"\n",
    "    Simulate a senator's buy and sell orders, and calculate the\n",
    "    return.\n",
    "    \"\"\"\n",
    "    stocks = defaultdict(int)\n",
    "    # Value of portfolio at various timepoints to calculate return\n",
    "    portfolio_value_before_tx = []\n",
    "    portfolio_value_after_tx = []\n",
    "    tx_dates = []\n",
    "    rows = rows.sort_values(by=date_col)\n",
    "    for _, row in rows.iterrows():\n",
    "        date = row[date_col]\n",
    "        if date_col == 'file_date':\n",
    "            # We can't execute the trade the same day\n",
    "            date += dt.timedelta(days=1)\n",
    "        try:\n",
    "            stock_price = ticker_at_date(row['ticker'], date)\n",
    "        except IndexError as e:\n",
    "            # Skip the row if we're missing ticker data\n",
    "            continue\n",
    "        value_before_tx = portfolio_value(stocks, date)\n",
    "        if 'Purchase' in row['order_type']:\n",
    "            tx_amt = row['tx_estimate']\n",
    "            n_units = tx_amt / ticker_at_date(row['ticker'], date)\n",
    "            stocks[row['ticker']] += n_units\n",
    "        elif 'Sale' in row['order_type']:\n",
    "            current_value = stock_price * stocks[row['ticker']]\n",
    "            if 'Full' in row['order_type'] or\\\n",
    "                same_bucket(row['tx_estimate'], current_value):\n",
    "                stocks[row['ticker']] = 0\n",
    "            else:\n",
    "                new_n_units = stocks[row['ticker']] - \\\n",
    "                    row['tx_estimate'] / stock_price\n",
    "                stocks[row['ticker']] = max(0, new_n_units)\n",
    "        portfolio_value_before_tx.append(value_before_tx)\n",
    "        portfolio_value_after_tx.append(portfolio_value(stocks, date))\n",
    "        tx_dates.append(date)\n",
    "    return calculate_return(\n",
    "        portfolio_value_before_tx,\n",
    "        portfolio_value_after_tx,\n",
    "        begin_date=min(rows[date_col]),\n",
    "        end_date=max(rows[date_col]),\n",
    "        tx_dates=tx_dates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "senator_returns = []\n",
    "senator_tx_growth = {}\n",
    "senator_file_growth = {}\n",
    "senator_names = set(senators_tx['full_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell took my laptop about three hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_senators = {}\n",
    "print('{} senators total'.format(len(senator_names)))\n",
    "for n in senator_names:\n",
    "    print('Starting {}'.format(n))\n",
    "    if n in senator_tx_growth:\n",
    "        # Don't re-calculate for a given senator\n",
    "        continue\n",
    "    try:\n",
    "        tx_return = return_for_senator(\n",
    "            senators_tx[senators_tx['full_name'] == n],\n",
    "            date_col='tx_date')\n",
    "        file_return = return_for_senator(\n",
    "            senators_tx[senators_tx['full_name'] == n],\n",
    "            date_col='file_date')\n",
    "        senator_returns.append({\n",
    "            'full_name': n,\n",
    "            'tx_total_return': tx_return['portfolio_return'],\n",
    "            'tx_cagr': tx_return['annual_cagr'],\n",
    "            'file_total_return': file_return['portfolio_return'],\n",
    "            'file_cagr': file_return['annual_cagr']\n",
    "        })\n",
    "        senator_tx_growth[n] = tx_return['growth']\n",
    "        senator_file_growth[n] = file_return['growth']\n",
    "    except Exception as e:\n",
    "        print('Failed senator {0} with exception {1}'.format(n, e))\n",
    "        failed_senators[n] = e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the results to see the senators that outperformed the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_senator_growth(growth):\n",
    "    \"\"\" Plot the senator's portfolio growth against the S&P 500. \"\"\"\n",
    "    plt.plot_date(growth['date'], growth['cumulative_growth'], '-')\n",
    "    download_for_ticker('SPY')\n",
    "    spy = load_for_ticker('SPY')\n",
    "    spy = spy[(spy['date'] >= min(growth['date']))\n",
    "              & (spy['date'] <= max(growth['date']))]\n",
    "    spy_prices = spy['price']\n",
    "    spy_growth = np.cumprod(np.diff(spy_prices) / spy_prices[1:] + 1)\n",
    "    dates = spy['date'].iloc[1:]\n",
    "    plt.plot_date(dates, spy_growth, '-')\n",
    "    plt.show()\n",
    "    print('Earliest date: {}'.format(min(growth['date'])))\n",
    "    print('Latest date: {}'.format(max(growth['date'])))\n",
    "    print('Market return: {}'.format(\n",
    "        spy_prices.iloc[-1] / spy_prices.iloc[0]))\n",
    "    senator_growth = growth['cumulative_growth']\n",
    "    print('Senator return: {}'.format(\n",
    "        senator_growth.iloc[-1] / senator_growth.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "returns = pd.DataFrame(senator_returns)\n",
    "returns = returns[(returns['tx_total_return'] > returns['tx_cagr'])\n",
    "                  & (returns['tx_cagr'] > 0)]\n",
    "returns.sort_values('tx_cagr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_senator_growth(senator_tx_growth['Angus S King, Jr.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "Author: Neel Somani, Software Engineer\n",
    "\n",
    "Email: neel@berkeley.edu\n",
    "\n",
    "Website: https://www.ocf.berkeley.edu/~neel/\n",
    "\n",
    "Updated On: 2020-05-23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
